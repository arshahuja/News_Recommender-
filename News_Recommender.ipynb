{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "import gensim\n",
    "import pickle\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('news_articles.csv')['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    At least 14 people died and 17 others were inj...\n",
       " 1    TV actress Pratibha Tiwari  who is best known ...\n",
       " 2    The United States and South Korea began a join...\n",
       " 3    The relentless drive by Bengaluru s  Bangalore...\n",
       " 4    Punjab Gau Raksha Dal chief Satish Kumar and h...\n",
       " Name: Content, dtype: object, 4831)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(),len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all the ignored 9282 numbers from corpus \n",
    "ignored_numbers=pickle.load(open('ignored_numbers.pkl', 'rb'))\n",
    "for i in range(len(data)):\n",
    "    query = data[i].split()\n",
    "    resultwords  = [word for word in query if word not in ignored_numbers]\n",
    "    data[i] = ' '.join(resultwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "cleaned_data=[]\n",
    "tagged_data=[]\n",
    "for doc in data:\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in tokens if not w in stop_words]\n",
    "    #lemmatisation\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for tok in words:\n",
    "        tok=lemmatiser.lemmatize(tok)\n",
    "    cleaned_data.append(words)\n",
    "    #pos tagging\n",
    "    pos=pos_tag(words)\n",
    "    tagged_data.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store cleaned files\n",
    "with open('cleaned_data.pkl', 'wb') as f:\n",
    "    pickle.dump(cleaned_data,f)\n",
    "with open('tagged_data.pkl', 'wb') as f:\n",
    "    pickle.dump(tagged_data,f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load files\n",
    "cleaned_data=pickle.load(open('cleaned_data.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfidf function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer=TfidfVectorizer()\n",
    "def tfidf_scores(d):\n",
    "    tfidf=vectorizer.fit_transform(d)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data=[]\n",
    "for i in cleaned_data:\n",
    "    n_data.append(' '.join(i))\n",
    "new_data=pd.Series(n_data)    \n",
    "scores=tfidf_scores(n_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = gensim.models.KeyedVectors.load_word2vec_format('../wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45807"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vocab=list(vectorizer.vocabulary_.keys())\n",
    "dim=300\n",
    "en_ignored=[]\n",
    "en_w2vectors=np.ones((1,dim))\n",
    "for i in t_vocab:\n",
    "    if i in en_model:     \n",
    "        en_w2vectors=np.concatenate((en_w2vectors,en_model[i].reshape(1,-1)),axis=0)\n",
    "    else:\n",
    "        en_ignored.append(i)\n",
    "        en_w2vectors=np.concatenate((en_w2vectors,np.zeros((1,dim))),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignored_numbers = [s for s in en_ignored if s.isdigit()]\n",
    "len(ignored_numbers)\n",
    "pickle.dump(ignored_numbers,open('ignored_numbers.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12690"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36796, 300)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v=en_w2vectors[1:,:]\n",
    "w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(w2v,open('w2v.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v=scores*w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(d2v,open('d2v.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4831, 300)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v=pickle.load(open('d2v.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.cluster.kmeans import KMeansClusterer\n",
    "num_clt=10\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "kclusterer = KMeansClusterer(num_clt, distance=cosine_distance, repeats=25)\n",
    "assigned_clusters = kclusterer.cluster(d2v, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_articles={}\n",
    "for i in range(10):\n",
    "    clt_articles[i]=np.where(np.array(assigned_clusters)==i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clt_articles,open('cluster.pickle','wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg. reading speed (200 wpm)\n",
    "speed=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in data:\n",
    "    l.append(np.array(i.split()).shape[0])\n",
    "#avg. length of doc (no. of words)\n",
    "avg_length=np.average(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.391989236183"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_time =avg_length/speed\n",
    "avg_time*60 #in seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "clt_articles=pickle.load(open('cluster.pickle','rb'))\n",
    "\n",
    "def generate_data(aid):\n",
    "    #Generate clickstream data \n",
    "    click_stream=np.random.binomial(1,0.75,500)\n",
    "    \n",
    "    # Generate time sample from three gaussian distributions\n",
    "    time = np.random.normal(5,0.5,60)      # just opened and closed\n",
    "    time = np.append(time, np.random.normal(30,10,160))  # read half/some part   \n",
    "    time = np.append(time, np.random.normal(80,10,270))   # read completely\n",
    "    time = np.append(time, np.random.normal(200,10,10))  # app left apened etc.\n",
    "    #generate 10 values for time\n",
    "    new_time=time.reshape(-1,1)*click_stream.reshape(-1,1)  \n",
    "    read_time=random.sample(list(new_time.ravel()),10)\n",
    "    click=np.ones((len(read_time),1))\n",
    "    for i in range(len(read_time)):\n",
    "        if read_time[i]==0:\n",
    "            click[i]=0\n",
    "    \n",
    "    #generating 10 random articles from corpus\n",
    "    if len(aid)==0:\n",
    "        aid=[]\n",
    "        for i in range(10):\n",
    "            aid.append(random.sample(list(itertools.chain.from_iterable(clt_articles[i])),1)[0])  \n",
    "    \n",
    "    #sort aid based on time        \n",
    "    read_time=np.array(read_time)\n",
    "    n_liked=len(set(read_time[read_time>50]).intersection(set(read_time[read_time<150])))\n",
    "    sorted_=[x for _,x in sorted(zip(read_time,aid),reverse=True)]\n",
    "    liked_=[x for _,x in sorted(zip(read_time,aid),reverse=True)][:n_liked]\n",
    "    \n",
    "    #calculating a_rnk and liked articles\n",
    "    rnk={}\n",
    "    for j in range(len(sorted_)):\n",
    "        rnk[sorted_[j]]=j+1    \n",
    "    a_rnk=[]\n",
    "    liked=np.zeros((10,1))\n",
    "    for k in range(len(aid)):\n",
    "        a_rnk.append(rnk[aid[k]])\n",
    "        if aid[k] in liked_:\n",
    "            liked[k]=1\n",
    "    \n",
    "    \n",
    "    return aid,read_time,click,a_rnk,liked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class user():\n",
    "    id_generator = itertools.count(1)\n",
    "    def __init__(self,name,article):\n",
    "        self.name=name\n",
    "        self.id =next(self.id_generator)\n",
    "        #self.sid=session\n",
    "        self.aid,self.time,self.click,self.a_rnk,self.liked=generate_data(article)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_data(session_id,articles):\n",
    "    \n",
    "    if len(articles)!=0:\n",
    "        user1=user('u1',articles[0])\n",
    "        user2=user('u2',articles[1])\n",
    "        user3=user('u3',articles[2])\n",
    "        user4=user('u4',articles[3])\n",
    "        user5=user('u5',articles[4])\n",
    "    else:\n",
    "        user1=user('u1',[])\n",
    "        user2=user('u2',[])\n",
    "        user3=user('u3',[])\n",
    "        user4=user('u4',[])\n",
    "        user5=user('u5',[])\n",
    "\n",
    "    #creating a dataframe for user profiling\n",
    "    up=pd.DataFrame()\n",
    "    uid=[]\n",
    "    aid=[]\n",
    "    time=[]\n",
    "    click=[]\n",
    "    a_rnk=[]\n",
    "    liked=[]\n",
    "    \n",
    "    user_names=[user1,user2,user3,user4,user5]    \n",
    "    \n",
    "    for s in range(session_id):\n",
    "        if s==0:\n",
    "            for names in user_names:\n",
    "                uid.append([names.id]*10)\n",
    "                aid.append(names.aid)\n",
    "                time.append(names.time)\n",
    "                click.append(names.click)\n",
    "                a_rnk.append(names.a_rnk)\n",
    "                liked.append(names.liked)\n",
    "                \n",
    "        else:    \n",
    "            for n,names in enumerate(user_names): \n",
    "                aid_,time_,click_,a_rnk_,liked_=generate_data([])\n",
    "                uid.append([names.id]*10)\n",
    "                aid.append(aid_)\n",
    "                time.append(time_)\n",
    "                click.append(click_)\n",
    "                a_rnk.append(a_rnk_)\n",
    "                liked.append(liked_)\n",
    "            \n",
    "    up['uid']=np.array(uid).ravel()\n",
    "    up['sid']=np.sort(list(range(1,session_id+1))*50)\n",
    "    up['aid']=np.array(aid).reshape(-1,1)\n",
    "    up['time']=np.array(time).reshape(-1,1)\n",
    "    up['click']=np.array(click).reshape(-1,1)\n",
    "    up['a_rnk']=np.array(a_rnk).reshape(-1,1)\n",
    "    up['liked']=np.array(liked).reshape(-1,1)\n",
    "\n",
    "    return up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data=user_data(4,[])\n",
    "pickle.dump(dummy_data,open('user_data.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity function\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def similar(d2v,liked,n):\n",
    "    cos_sim=cosine_similarity(d2v,liked)\n",
    "    return cos_sim.ravel().argsort()[-(n+1):-1][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v=pickle.load(open('d2v.pickle','rb'))\n",
    "data=pickle.load(open('user_data.pickle','rb'))\n",
    "mean_time=data.groupby('aid').mean()['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>aid</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>a_rnk</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>5.563829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>68.773441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4633</td>\n",
       "      <td>52.278529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1326</td>\n",
       "      <td>96.003458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  sid   aid       time  click  a_rnk  liked\n",
       "0    1    1   228   5.563829    1.0      6    0.0\n",
       "1    1    1   256  68.773441    1.0      2    1.0\n",
       "2    1    1   606   0.000000    0.0      9    0.0\n",
       "3    1    1  4633  52.278529    1.0      3    1.0\n",
       "4    1    1  1326  96.003458    1.0      1    1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new(data,d2v):\n",
    "    \n",
    "    #average vector of every user /user profile\n",
    "    profile=[]\n",
    "    for j in range(5):\n",
    "        temp=[]\n",
    "        for i in data.loc[(data['uid'] ==j+1) & data['liked']==1]['aid'] :    \n",
    "            weight=int((data[data['aid']==i]['time']/mean_time[i]).values[0])\n",
    "            temp.append(d2v[i]*weight)  \n",
    "        profile.append(np.mean(temp,axis=0)) \n",
    "\n",
    "    #based on all users (2)\n",
    "    all_avg=np.mean(profile,axis=0)  #average vector from all users\n",
    "    trending=similar(d2v,all_avg.reshape(1,-1),2)\n",
    "    \n",
    "\n",
    "    #based on user's history (6)\n",
    "    history=[]\n",
    "    for vector in profile:\n",
    "        history.append(similar(d2v,vector.reshape(1,-1),6))\n",
    "    \n",
    "\n",
    "    #based on similar users (2)\n",
    "    sim_users=np.ones((5,5))\n",
    "    for i in range(len(profile)):\n",
    "        for j in range(len(profile)):\n",
    "            sim_users[i][j]=cosine_similarity(profile[i].reshape(1,-1),profile[j].reshape(1,-1))\n",
    "    sim_users=sim_users.argsort()[:,-3:-1] \n",
    "    #print(sim_users)\n",
    "\n",
    "    #articles based on similar users \n",
    "    sim_art=[]\n",
    "    for i,j in sim_users:\n",
    "        temp=[]\n",
    "        temp.append(profile[i])\n",
    "        temp.append(profile[j])\n",
    "        sim_art.append(similar(d2v,np.mean(np.array(temp),axis=0).reshape(1,-1),2))\n",
    "    #return history,sim_art,trending\n",
    "    new_aid=[]\n",
    "    for i in range(5):\n",
    "        temp=[]\n",
    "        temp.extend(history[i])\n",
    "        temp.extend(sim_art[i])\n",
    "        temp.extend(trending)\n",
    "\n",
    "        new_aid.append(temp)\n",
    "\n",
    "    return new_aid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_articles=new(data,d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_new(new_articles):\n",
    "    d=pd.DataFrame(columns=['uid','sid','aid','time','click','a_rnk','liked'])\n",
    "    uid=[]\n",
    "    sid=[]\n",
    "    aid=[]\n",
    "    time=[]\n",
    "    click=[]\n",
    "    a_rnk=[]\n",
    "    liked=[]\n",
    "    for n in range(5):\n",
    "        uid.append([n+1]*10)\n",
    "        sid.append([6]*10)\n",
    "        aid.append(new_articles[n])\n",
    "        time.append(['-']*10)\n",
    "        click.append(['-']*10)\n",
    "        a_rnk.append(list(range(1,11)))\n",
    "        liked.append(['-']*10)\n",
    "    d['uid']=np.array(uid).ravel()\n",
    "    d['sid']=np.array(sid).ravel()\n",
    "    d['aid']=np.array(aid).ravel()\n",
    "    d['time']=np.array(time).ravel()\n",
    "    d['click']=np.array(click).ravel()\n",
    "    d['a_rnk']=np.array(a_rnk).ravel()\n",
    "    d['liked']=np.array(liked).ravel()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>aid</th>\n",
       "      <th>time</th>\n",
       "      <th>click</th>\n",
       "      <th>a_rnk</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1474</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>898</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1456</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1008</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4822</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  sid   aid time click  a_rnk liked\n",
       "0    1    6  1474    -     -      1     -\n",
       "1    1    6   898    -     -      2     -\n",
       "2    1    6  1456    -     -      3     -\n",
       "3    1    6  1008    -     -      4     -\n",
       "4    1    6  4822    -     -      5     -"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_new(new_articles).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
